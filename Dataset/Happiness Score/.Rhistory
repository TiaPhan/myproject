summary(uci)
uci[["hours_per_week"]]=ordered(cut(uci[["hours_per_week"]],c(0,25,40,60,168),labels = c("Part-time","Full-time","Over-time","Workaholic"))
uci[["capital_gain"]]=ordered(cut(uci[["capital_gain"]][uci[["captal_gain"]]>0),Inf)),labels=c("None","Low","High"))
uci[["hours_per_week"]]=ordered(cut(uci[["hours_per_week"]],c(0,25,40,60,168)),labels = c("Part-time","Full-time","Over-time","Workaholic"))
uci[["capital_gain"]]=ordered(cut(uci[["capital_gain"]][uci[["captal_gain"]]>0),Inf)),labels=c("None","Low","High"))
uci[["capital-gain"]]=ordered(cut(uci[["capital-gain"]][uci[["captal-gain"]]>0),Inf)),labels=c("None","Low","High"))
uci[["capital-gain"]]=ordered(cut(uci[["capital-gain"]],c(-Inf,0,median(uci[["capital-gain"]][uci[["captal-gain"]]>0),Inf)),labels=c("None","Low","High"))
summary(uci)
uci[["hours_per_week"]]=ordered(cut(uci[["hours_per_week"]],c(0,25,40,60,168)),labels = c("Part-time","Full-time","Over-time","Workaholic"))
as.numeric('hours_per_week')
uci[["hours_per_week"]]=ordered(cut(uci[["hours_per_week"]],c(0,25,40,60,168)),labels = c("Part-time","Full-time","Over-time","Workaholic"))
library(Warning Messages)
library("Warning Messages")
class(hours_per_week)
class('hours_per_week')
uci[["hours_per_week"]]=ordered(cut(uci[[ "hours_per_week"]], c(0,25,40,60,168)),labels = c("Part-time","Full-time","Over-time","Workaholic"))
as.numeric('hours_per_week')
warning(as.numeric('hours_per_week'))
supresswarning(as.numeric('hours_per_week'))
as.factor(uci$`hours-per-week`)
uci[["hours_per_week"]]=ordered(cut(uci[[ "hours_per_week"]], c(0,25,40,60,168)),labels = c("Part-time","Full-time","Over-time","Workaholic"))
as.numeric(uci$`hours-per-week`)
uci[["hours_per_week"]]=ordered(cut(uci[[ "hours_per_week"]], c(0,25,40,60,168)),labels = c("Part-time","Full-time","Over-time","Workaholic"))
age
uci$age
class(age)
class('age')
uci[["hours-per-week"]]=ordered(cut(uci[["hours-per-week"]],c(0,25,40,168)),labels=c("Part-time","Full-time","Over-time","Workaholic"))
uci[["hours-per-week"]]=ordered(cut(uci[["hours-per-week"]],c(0,25,40,60,168)),labels=c("Part-time","Full-time","Over-time","Workaholic"))
uci[["capital-gain"]]=ordered(cut(uci[["capital-gain"]],c(-Inf,0,median(uci[["capital-gain"]][uci[["captal-gain"]]>0),Inf)),labels=c("None","Low","High"))
uci[["capital-gain"]]=ordered(cut(uci[["capital-gain"]],c(-Inf,0,median(uci[["capital-gain"]],Inf)),labels=c("None","Low","High"))
uci[["capital-gain"]]=ordered(cut(uci[["capital-gain"]],c(-Inf,0,median(uci[["capital-gain"]],Inf)),labels=c("None","Low","High"))
uci[["capital-gain"]]=ordered(cut(uci[["capital-gain"]],c(-Inf,0,median(uci[["capital-gain"]][uci[["capital-gain"]]>0],Inf)),labels=c("None","Low","High"))
uci[["capital-gain"]]=ordered(cut(uci[["capital-gain"]],c(-Inf,0,median(uci[["capital-gain"]][uci[["capital-gain"]]>0],Inf)),labels=c("None","Low","High"))
uci[["capital-gain"]]=ordered(cut(uci[["capital-gain"]],c(-Inf,0,median(uci[["capital-gain"]][uci[["capital-gain"]]>0],Inf)),labels=c("None","Low","High"))
uci[["capital-gain"]]=ordered(cut(uci[["capital-gain"]],c(-Inf,0,median(uci[["capital-gain"]][uci[["capital-gain"]]>0],Inf)),labels=c("None","Low","High"))
uci[["capital-gain"]]=ordered(cut(uci[["capital-gain"]],c(-Inf,0,median(uci[["capital-gain"]],Inf),labels=c("None","Low","High"))
summary(uci)
summary(uci)
uci[["capital-gain"]]=ordered(cut(uci[["capital-gain"]],c(-Inf,0,median(uci[["capital-gain"]][uci[[capital-gain]]>0],Inf),labels=c("None","Low","High"))
uci[["capital-gain"]]=ordered(cut(uci[["capital-gain"]],c(-Inf,0,median(uci[["capital-gain"]][uci[[capital-gain]]>0],Inf),labels=c("None","Low","High"))
AdultUCI[[ "capital-gain"]] <- ordered(cut(AdultUCI[[ "capital-gain"]],
+ c(-Inf,0,median(AdultUCI[[ "capital-gain"]][AdultUCI[[ "capital-gain"]]>0]),Inf)),labels = c("None", "Low", "High"))
uci[[ "capital-gain"]] <- ordered(cut(uci[[ "capital-gain"]],c(-Inf,0,median(uci[[ "capital-gain"]][uci[[ "capital-gain"]]>0]),Inf)),labels = c("None", "Low", "High"))
uci(1:2,)
data("AdultUCI")
library('arules')
data("AdultUCI")
uci=AdultUCI
uci(1:2,)
uci[1:2,]
uci(1:2)
uci[1:2]
uci[["fnlwgt"]] = NULL
uci[["education-num"]] = NULL
uci[["age"]] = ordered(cut(uci[["age"]], c(15,25,45,65,100)), labels=c("Young","Middle-age","Senior","Old"))
uci[["hours-per-week"]] = ordered(cut(uci[["hours-per-week"]], c(0,25,40,60,168)), labels=c("Part-time", "Full-time","Overtime","Workaholic"))
uci[["capital-gain"]] = ordered(cut(uci[["capital-gain"]], c(-Inf,0, median(uci[["capital-gain"]][uci[["capital-gain"]]>0]), Inf)), labels=c("None", "Low", "High"))
uci[["capital-loss"]] = ordered(cut(uci[["capital-loss"]],c(-Inf,0,median(uci[["capital-loss"]][uci[["capital-loss"]]>0]),Inf)), labels=c("None", "Low", "High"))
str(uci)
adult=(uci,"transaction")
adult=as(uci,"transaction")
adult=as(uci,"transactions")
summary(adult)
itemFrequencyPlot(adult)
window()
itemFrequencyPlot(adult)
window()
windows()
itemFrequencyPlot(adult)
windows()
itemFrequencyPlot(adult)
rules=apriori(adult,parameter = list(supp=0.01, conf=0.06 ))
rules_income_small=subset(rules,subset = rhs%in% "income=small"&lift>1.2)
rules_income_large=subset(rules,subset = rhs%in% "income_large"&lift>1.2)
rules_income_large=subset(rules,subset = rhs%in% "income=large"&lift>1.2)
inspect(head(rules_income_small, n=3, by = "confidence")
show(rules_income_small)
inspect(head(rules_income_small, n=3, by = "confidence"))
rules_income_small
inspect(head(rules_income_large, n=3, by = "confidence"))
inspect(head(rules_income_small, n=3, by = "confidence"))
knitr::opts_chunk$set(echo = TRUE)
inspect(head(rules_income_small, n=3, by = "confidence"))
data("retail")
plot("retail")
library(ggplot2)
plot("retail")
View("retail")
data("Retail Market Basket ")
data("Retail Market")
install.packages(packrat)
install.packages("packrat")
library(C50)
computer=read.csv("da_computer3.txt")
attach(computer)
?attach  #attach your database to R
?na.omit #removed all NAs
ff=na.omit(computer)
ftree=tree(age~., data=ff);ftree
names(ff)
prop.table(table(ff$buy)) #buying percentage in ff dataset
install.packages("tree")
library(tree)
?trees
library(dplyr)
library(tidyr)
ff=ff%>%separate(edu.age.marri.income.city.buy, c("edu","age","marri","income","city","buy"))
names(ff)
ftree=tree(buy~.,data=ff);ftree
summary(ftree)
class(ftree)
head(ftree)
plot(ftree)
text(ftree)
show(ftree)
ind <- sample(2,nrow(ff),replace=TRUE,prob=c(0.7,0.3)) #The common practice is to split the data 80/20, 80 percent of the data serves to train the model, and 20 percent to make predictions.
?sample
traindata <- ff[ind==1,]
traindata
testdata = ff[ind==2,]
testdata
create_buy_test <- function(ff, size = 0.8, buy = TRUE) {
n_row = nrow(ff)
total_row = size * n_row
buy_sample < - 1: total_row
if (train == TRUE) {
return (data[ff, ])
} else {
return (data[-ff, ])
}
}
data_test <- create_buy_test(buy, 0.8, buy = FALSE)
prop.table(table(traindata$buy)) #buying percentage in traindata set
install.packages("rpart")    #regression plot
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
fit <- rpart(buy~., data = traindata, method = 'class')
rpart.plot(fit, extra = 106)
predict_unseen <-predict(fit, testdata, type = 'class')  #predict which passengers are more likely to survive after the collision from the test set. It means, you will know among those 209 passengers, which one will buy or not.
table_mat <- table(testdata$buy, predict_unseen)
install.packages("rpart")
COVID19_line_list_data <- read.csv("C:/Users/Tia Phan/Downloads/COVID19_line_list_data.csv")
View(COVID19_line_list_data)
data<- read.csv("C:/Users/Tia Phan/Downloads/COVID19_line_list_data.csv")
describe(data)
install.packages(Hmisc)
install.packages("Hmisc")
install.packages("Hmisc")
data<- read.csv("C:/Users/Tia Phan/Downloads/COVID19_line_list_data.csv")
describe(data)
describe
library(Hmisc)
describe(data)
data$death_dummy=as.integer(data$death != 0)
dead=subset(data,death_dummy==1)
alive=subset(data,death_dummy==0)
mean(dead$age)
mean(dead$age, na.rm = TRUE)
mean(alive$age, na.rm=TRUE)
t.test(dead$sge,alive$age,alternative="two.sided",conf.level=0.99)
t.test(dead$age,alive$age,alternative="two.sided",conf.level=0.99)
t.test(dead$age,alive$age,alternative="two.sided",conf.level=0.5)
male=subset(data,gender=="male")
female=subset(data,gender=="female")
mean(female$death_dummy)
mean(male$death_dummy)
t.test(male$death_dummy,female$death_dummy,alternative = "two.sided",conf.level = 0.95)
survey=read_excel('Survey.xlxs')
survey=read.xlsx('Survey.xlsx')
install.packages("tseries")
install.packages("timeSeries")
install.packages("forecast")
tw0050 <- getSymbols("0050.TW", auto.assign = FALSE, from="2021-05" ,to="2022-05-01")
tw0050 <- getSymbols("0050.TW", auto.assign = FALSE, from="2020-05" ,to="2022-05")
tw0050 <- getSymbols("0050.TW", auto.assign = FALSE, from="2020-05" to="2022-05")
tw0050 <- getSymbols("0050.TW", auto.assign = FALSE, from="2000-01-01" ,to="2022-05-01")
tw0050 <- getSymbols("0050.TW", auto.assign = FALSE, from="2000-01-01" ,to="2022-05-01")
install.packages("tseries")
install.packages("timeSeries")
install.packages("forecast")
sp500=new.env()
gspc <- getSymbols("GSPC", env = sp500, src = "yahoo", from = as.Date("1960-01-04"), to = as.Date("2009-01-01"))
library(quantmod)
sp500=new.env()
gspc <- getSymbols("GSPC", env = sp500, src = "yahoo", from = as.Date("1960-01-04"), to = as.Date("2009-01-01"))
install.packages('mlr3')
library(mlr3)
install.packages("MASS")
install.packages("caTools")
install.packages("neuralnet")
install.packages("knitr")
library(MASS)
library(caTools)
library(neuralnet)
library(ggplot2)
library(knitr)
head(Boston)
is.na(Boston)
sum(is.na(Boston))
split <- sample.split(scaled$medv, SplitRatio = 0.75)
train <- subset(scaled, split == T)
test <- subset(scaled, split == F)
scaled.data <- scale(data, center = mins, scale = maxs - mins)
scaled <- as.data.frame(scaled.data)
#Scale data
scaled.data <- scale(data, center = mins, scale = maxs - mins)
mins <- apply(data, MARGIN=2, min)
maxs <- apply(data, MARGIN=2, max)
any(is.na(Boston))
data <- Boston
maxs <- apply(data, MARGIN=2, max)
mins <- apply(data, MARGIN=2, min)
scaled.data <- scale(data, center = mins, scale = maxs - mins)
scaled <- as.data.frame(scaled.data)
split <- sample.split(scaled$medv, SplitRatio = 0.75)
train <- subset(scaled, split == T)
test <- subset(scaled, split == F)
n <- names(train)
f <- as.formula(paste("medv ~", paste(n[!n %in% "medv"], collapse = " + ")))
nn <- neuralnet(f, data = train, hidden = c(5,3), linear.output = TRUE)
plot(nn)
predicted.nn.values <- compute(nn, test[1:13])
str(predicted.nn.values)
true.predictions <- predicted.nn.values$net.result *
(max(data$medv) - min(data$medv)) + min(data$medv)
set.seed(12345)
fit.lm <- lm(medv~.,data = train)
rmse.lm <- sqrt(sum((pred.lm - testing$medv)^2)/
length(testing$MEDV))
c(RMSE = rmse.lm, R2 = summary(fit.lm)$r.squared)
pred.lm <- predict(fit.lm, newdata = test)
rmse.lm <- sqrt(sum((pred.lm - testing$medv)^2)/
length(testing$MEDV))
c(RMSE = rmse.lm, R2 = summary(fit.lm)$r.squared)
rmse.lm <- sqrt(sum((pred.lm - test$medv)^2)/
length(test$medv))
c(RMSE = rmse.lm, R2 = summary(fit.lm)$r.squared)
test.r <- (test$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
MSE.nn <- sum((test.r - true.predictions)^2)/nrow(test_)
test.r <- (test$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
MSE.nn <- sum((test.r - true.predictions)^2)/nrow(test)
print(paste(MSE.lm,MSE.nn))
library(MASS)
library(caTools)
library(neuralnet)
library(ggplot2)
library(knitr)
any(is.na(Boston))
set.seed(500)
data=Boston
apply(data,2,function(x) sum(is.na(x)))
index <- sample(1:nrow(data),round(0.75*nrow(data)))
train <- data[index,]
test <- data[-index,]
lm.fit <- glm(medv~., data=train)
summary(lm.fit)
pr.lm <- predict(lm.fit,test)
MSE.lm <- sum((pr.lm - test$medv)^2)/nrow(test)
maxs <- apply(data, 2, max)
mins <- apply(data, 2, min)
scaled <- as.data.frame(scale(data, center = mins, scale = maxs - mins))
train_ <- scaled[index,]
test_ <- scaled[-index,]
n <- names(train_)
f <- as.formula(paste("medv ~", paste(n[!n %in% "medv"], collapse = " + ")))
nn <- neuralnet(f,data=train_,hidden=c(5,3),linear.output=T)
plot(nn)
pr.nn <- compute(nn,test_[,1:13])
pr.nn_ <- pr.nn$net.result*(max(data$medv)-min(data$medv))+min(data$medv)
test.r <- (test_$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
print(paste(MSE.lm,MSE.nn))
par(mfrow=c(1,2))
plot(test$medv,pr.nn_,col='red',main='Real vs predicted NN',pch=18,cex=0.7)
abline(0,1,lwd=2)
legend('bottomright',legend='NN',pch=18,col='red', bty='n')
plot(test$medv,pr.lm,col='blue',main='Real vs predicted lm',pch=18, cex=0.7)
abline(0,1,lwd=2)
legend('bottomright',legend='LM',pch=18,col='blue', bty='n', cex=.95)
plot(test$medv,pr.lm,col='blue',main='Real vs predicted lm',pch=18, cex=0.7)
abline(0,1,lwd=2)
plot(test$medv,pr.lm,col='blue',main='Real vs predicted lm',pch=18, cex=0.7)
abline(0,1,lwd=2)
legend('bottomright',legend='LM',pch=18,col='blue', bty='n', cex=.95)
plot(test$medv,pr.nn_,col='red',main='Real vs predicted NN',pch=18,cex=0.7)
points(test$medv,pr.lm,col='blue',pch=18,cex=0.7)
abline(0,1,lwd=2)
legend('bottomright',legend=c('NN','LM'),pch=18,col=c('red','blue'))
library(boot)
set.seed(200)
lm.fit <- glm(medv~.,data=data)
cv.glm(data,lm.fit,K=10)$delta[1]
set.seed(450)
cv.error <- NULL
k <- 10
library(plyr)
pbar <- create_progress_bar('text')
pbar$init(k)
for(i in 1:k){
index <- sample(1:nrow(data),round(0.9*nrow(data)))
train.cv <- scaled[index,]
test.cv <- scaled[-index,]
nn <- neuralnet(f,data=train.cv,hidden=c(5,2),linear.output=T)
pr.nn <- compute(nn,test.cv[,1:13])
pr.nn <- pr.nn$net.result*(max(data$medv)-min(data$medv))+min(data$medv)
test.cv.r <- (test.cv$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
cv.error[i] <- sum((test.cv.r - pr.nn)^2)/nrow(test.cv)
pbar$step()
}
mean(cv.error)
cv.error
boxplot(cv.error,xlab='MSE CV',col='cyan',
border='blue',names='CV error (MSE)',
main='CV error (MSE) for NN',horizontal=TRUE)
plot(nn)
library(readr)
hp1 <- read_csv("C:/Users/Tia Phan/OneDrive/Máy tính/a/Dataset/Happiness Score/new-world-happiness-report-2021.csv")
View(hp1)
library(ggplot2)
library(dplyr)
library(arules)
cor(hp1[, unlist(lapply(hp1, is.numeric))])
# Correlation
plot(hp1, main="Correlation")
hp1$`Ladder score in Dystopia`=NULL
hp1$`Explained by: Log GDP per capita`=NULL
hp1$`Explained by: Social support`=NULL
hp1$`Explained by: Healthy life expectancy`=NULL
hp1$`Explained by: Freedom to make life choices`=NULL
hp1$`Explained by: Generosity`=NULL
hp1$`Explained by: Perceptions of corruption`=NULL
hp1$`Standard error of ladder score`=NULL
hp1$upperwhisker=NULL
hp1$lowerwhisker=NULL
hp1$`Dystopia + residual`=NULL
# Correlation
plot(hp1, main="Correlation")
heatmap(hp1)
cor(hp1[, unlist(lapply(hp1, is.numeric))])
heatmap(cor(hp1))
heatmap(cor(hp1, is.numeric))
heatmap(cor(hp1[, unlist(lapply(hp1, is.numeric))]))
install.packages("metan")
install.packages("metan")
install.packages("metan")
setwd("C:/Users/Tia Phan/OneDrive/Máy tính/a/Dataset/Happiness Score")
library(readxl)
happiness_1921 <- read_excel("C:/Users/Tia Phan/OneDrive/Máy tính/a/Dataset/Happiness Score/happiness 1921.xlsx")
View(happiness_1921)
happiness_1921 <- read_excel("C:/Users/Tia Phan/OneDrive/Máy tính/a/Dataset/Happiness Score/happiness 1921_1.xlsx")
View(happiness_1921)
View(happiness_1921)
happiness_1921 <- read_excel("C:/Users/Tia Phan/OneDrive/Máy tính/a/Dataset/Happiness Score/happiness 1921_1.xlsx")
View(happiness_1921)
library(ggplot2)
library(dplyr)
library(arules)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(dplyr)
library(tidyr)
library(sf)
library(ggcorrplot)
library(choroplethr)
library(ggmap)
Y2019=happiness_1921[which(happiness_1921$Year==2019),]
Y2020=happiness_1921[happiness_1921$Year==2020,]
Y2021=happiness_1921[happiness_1921$Year==2021,]
top_6_2019=head(arrange(Y2019,desc(Score)))
corr_data <- happiness_1921 %>% select(Score, GDP_per_capita, Social_support, Health, Freedom, Generosity, Corruption)
corr <- round(cor(corr_data), 1)
corr
ggcorrplot(corr, ggtheme = ggplot2::theme_minimal(),
colors = c("#FDEE87", "white", "#50C878"), lab=TRUE, title ="Overall Correlation")
ggplot(data=top_6_2019, aes(x=Country, y=Score)) +
geom_bar(stat="identity", fill="#FDEE87") + coord_flip() + theme_linedraw() + ggtitle("2019 Top 6 Happiest Countries") + xlab("Countries") + ylab("Ladder Score")
top_6_2020=head(arrange(Y2020,desc(Score)))
top_6_2021=head(arrange(Y2021,desc(Score)))
# Horizontal bar Plot
ggplot(data=top_6_2020, aes(x=Country, y=Score)) +
geom_bar(stat="identity", fill="#FDEE87") + coord_flip() + theme_linedraw() + ggtitle("2020 Top 6 Happiest Countries") + xlab("Countries") + ylab("Ladder Score")
# Horizontal bar Plot
ggplot(data=top_6_2021, aes(x=Country, y=Score)) +
geom_bar(stat="identity", fill="#FDEE87") + coord_flip() + theme_linedraw() + ggtitle("2021 Top 6 Happiest Countries") + xlab("Countries") + ylab("Ladder Score")
ggplot(data=happiness_1921,aes(x=Country,y=Score))+geom_col(aes(fill=Year),width=0.8)
ggplot(data=happiness_1921,aes(x=Country.shorted,y=Score))+geom_col(aes(fill=Year),width=0.8)
happiness_1921 <- read_excel("C:/Users/Tia Phan/OneDrive/Máy tính/a/Dataset/Happiness Score/happiness 1921_1.xlsx")
View(happiness_1921)
ggplot(data=happiness_1921,aes(x=Country.shorted,y=Score))+geom_col(aes(fill=Year),width=0.8)
ggplot(data=happiness_1921,aes(x=Cou,y=Score))+geom_col(aes(fill=Year),width=0.8)
ggplot(happiness_1921,aes(x=Freedom,y=Score))+geom_point(col="pink")+geom_smooth(data=happiness_1921,aes(x=Freedom,y=Score,color="1"),formula = y~x, method="lm")
boxplot(happiness_1921$Score~happiness_1921$Regional,col=rainbow(length(unique(happiness_1921$Regional))),cex.axis=0.5)
# Linear Regression
library(caTools)
set.seed(123)
split2=sample.split(happiness_1921$Score, SplitRatio = 0.8)
training_set2=subset(happiness_1921, split2==TRUE)
test_set2=subset(happiness_1921, split2==FALSE)
regressor1=lm(formula=Score~GDP_per_capita+Social_support+Generosity+Corruption+Freedom+Health, data=training_set2)
summary(regressor1)
regressor2=lm(formula=Score~GDP_per_capita+Social_support+Generosity+Corruption, data=training_set2)
summary(regressor2)
regressor3=lm(formula=Score~Social_support+Generosity+Corruption, data=training_set2)
summary(regressor3)
pred=regressor2$fitted.values
tally_table=data.frame(actual=training_set2$Score, predicted=pred)
mape=mean(abs(tally_table$actual-tally_table$predicted)/tally_table$actual)
accuracy=1-mape
cat("The accuracy on the train data is:",accuracy)
pred_test2=predict(newdata=test_set2,regressor2)
tally_table=data.frame(actual=test_set2$Score, predicted=pred_test2)
mape=mean(abs(tally_table$actual-tally_table$predicted)/tally_table$actual)
accuracy=1-mape
cat(" and the accuracy on the test data is:",accuracy)
# Decision Tree
library(tree)
train=sample(1:nrow(happiness_1921),nrow(happiness_1921)/2)
tree.house=tree(Score~GDP_per_capita+Social_support+Generosity+Corruption,happiness_1921,subset=train)
summary(tree.house)
plot(tree.house)
text(tree.house)
yhat=predict(happiness_1921,newdata = happiness_1921[-train,])
house.test=happiness_1921[-train,"Score"]
mse=mean((yhat-house.test)^2)
mse
yhat=predict(happiness_1921,newdata = happiness_1921[-train,])
israel = hap2021[which(hap2021$Country=="Israel"),]
zimbabwe=hap2021[which(hap2021$Country=="Zimbabwe"),]
#CLustering
hap2021 <- read_excel("C:/Users/Tia Phan/OneDrive/Máy tính/a/Dataset/Happiness Score/hap2021.xlsx")
israel = hap2021[which(hap2021$Country=="Israel"),]
zimbabwe=hap2021[which(hap2021$Country=="Zimbabwe"),]
# Plot comparing map
ggplot(hap2021, aes(x=Social.support)) +
geom_histogram(binwidth=.2, fill="#50C878") + ggtitle("2021 Social Support") + xlab("Social support") + ylab("Country Count") + geom_vline(data=zimbabwe, aes(xintercept=Social.support, color="#E13F2A"),linetype="solid") + geom_vline(data=israel, aes(xintercept=Social.support, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("zimbabwe", "israel")) + theme_linedraw()
view(hap2021)
# Plot comparing map
ggplot(hap2021, aes(x=Social_support)) +
geom_histogram(binwidth=.2, fill="#50C878") + ggtitle("2021 Social Support") + xlab("Social support") + ylab("Country Count") + geom_vline(data=zimbabwe, aes(xintercept=Social_support, color="#E13F2A"),linetype="solid") + geom_vline(data=israel, aes(xintercept=Social_support, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("zimbabwe", "israel")) + theme_linedraw()
ggplot(happiness_1921,aes(Rank,Score,color=Regional))+geom_point()
set.seed(123)
happy_cluster=kmeans(happiness_1921[,5:11],centers = 10,iter.max = 100,nstart = 20)
happy_cluster
happy_cluster$size
data.with.cluster=data.frame(happiness_1921$Regional,happy_cluster$cluster)
data.with.cluster
summary(data.with.cluster)
happy_cluster=kmeans(happiness_1921[,6:12],centers = 10,iter.max = 100,nstart = 20)
happy_cluster
happy_cluster$size
data.with.cluster=data.frame(happiness_1921$Regional,happy_cluster$cluster)
data.with.cluster
summary(data.with.cluster)
# Box plot of cluster
boxplot(data.with.cluster$happy_cluster.cluster~happiness_1921$Regional,col=rainbow(length(unique(happiness_1921$Regional))),cex.axis=0.5)
avg.score.2019=mean(Y2019$Score)
avg.score.2019
avg.score.2020=mean(Y2020$Score)
avg.score.2020
avg.score.2021=mean(Y2020$Score)
avg.score.2021
avg.score.2021=mean(Y2021$Score)
avg.score.2021
# Plot comparing map
ggplot(hap2021, aes(x=Social_support)) +
geom_histogram(binwidth=.2, fill="#50C878") + ggtitle("2021 Social Support") + xlab("Social support") + ylab("Country Count") + geom_vline(data=zimbabwe, aes(xintercept=Social_support, color="#E13F2A"),linetype="solid") + geom_vline(data=israel, aes(xintercept=Social_support, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("zimbabwe", "israel")) + theme_linedraw()
ggplot(hap2021, aes(x=Social_support)) +
geom_histogram(binwidth=.2, fill="#50C878") + ggtitle("2021 Social Support") + xlab("Social support") + ylab("Country Count") + geom_vline(data=zimbabwe, aes(xintercept=Social_support, color="#E13F2A"),linetype="solid") + geom_vline(data=israel, aes(xintercept=Social_support, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("zimbabwe", "israel")) + theme_linedraw()
#CLustering
hap2021 <- read_excel("C:/Users/Tia Phan/OneDrive/Máy tính/a/Dataset/Happiness Score/hap2021.xlsx")
ggplot(hap2021, aes(x=Social_support)) +
geom_histogram(binwidth=.2, fill="#50C878") + ggtitle("2021 Social Support") + xlab("Social support") + ylab("Country Count") + geom_vline(data=zimbabwe, aes(xintercept=Social_support, color="#E13F2A"),linetype="solid") + geom_vline(data=israel, aes(xintercept=Social_support, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("zimbabwe", "israel")) + theme_linedraw()
# Plot comparing map
ggplot(hap2021, aes(x=Social_support)) +
geom_histogram(binwidth=.2, fill="#50C878") + ggtitle("2021 Social Support") + xlab("Social support") + ylab("Country Count") + geom_vline(data=israel, aes(xintercept=Social_support, color="#E13F2A"),linetype="solid") + geom_vline(data=zimbabwe, aes(xintercept=Social_support, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("israel", "zimbabwe")) + theme_linedraw()
dev.off
ggplot(hap2021, aes(x=Social_support)) +
geom_histogram(binwidth=.2, fill="#50C878") + ggtitle("2021 Social Support") + xlab("Social support") + ylab("Country Count") + geom_vline(data=israel, aes(xintercept=Social_support, color="#E13F2A"),linetype="solid") + geom_vline(data=zimbabwe, aes(xintercept=Social_support, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("israel", "zimbabwe")) + theme_linedraw()
ggplot(hap2021, aes(x=Social_support)) +
geom_histogram(binwidth=.2, fill="#50C878") + ggtitle("2021 Social Support") + xlab("Social support") + ylab("Country Count") + geom_vline(data=israel, aes(xintercept=Social_support, color="#E13F2A"),linetype="solid") + geom_vline(data=zimbabwe, aes(xintercept=Social_support, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("israel", "zimbabwe")) + theme_linedraw()
)
ggplot(hap2021, aes(x=Score)) +
geom_histogram(binwidth=.2, fill="#50C878") + ggtitle("2021 Social Support") + xlab("Social support") + ylab("Country Count") + geom_vline(data=israel, aes(xintercept=Score, color="#E13F2A"),linetype="solid") + geom_vline(data=zimbabwe, aes(xintercept=Social_support, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("israel", "zimbabwe")) + theme_linedraw()
israel = hap2021[which(hap2021$Country=="Israel"),]
zimbabwe=hap2021[which(hap2021$Country=="Zimbabwe"),]
israel$Score
zimbabwe$Score
ggplot(hap2021, aes(x=Score)) +
geom_histogram(binwidth=.2, fill="#50C878") + ggtitle("2021 Social Support") + xlab("Social support") + ylab("Country Count") + geom_vline(data=israel, aes(xintercept=Score, color="#E13F2A"),linetype="solid") + geom_vline(data=zimbabwe, aes(xintercept=Social_support, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("israel", "zimbabwe")) + theme_linedraw()
ggplot(hap2021, aes(x=Score)) +
geom_histogram(binwidth=.2, fill="#50C878") + ggtitle("2021 Social Support") + xlab("Social support") + ylab("Country Count") + geom_vline(data=israel, aes(xintercept=Score, color="#FF7F24"),linetype="solid") + geom_vline(data=zimbabwe, aes(xintercept=Social_support, color="#CAFF70"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("israel", "zimbabwe")) + theme_linedraw()
view(hap2021)
ggplot(hap2021, aes(x=Social_support)) +
geom_histogram(binwidth=.025, fill="#50C878") + ggtitle("2021 Social Support") + xlab("Social Support") + ylab("Country Count") + geom_vline(data=israel, aes(xintercept=Social_support, color="#E13F2A"),linetype="solid") + geom_vline(data=zimbabwe, aes(xintercept=Social_support, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("Zimbabwe", "Israel")) +theme_linedraw()
ggplot(hap2021, aes(x=GDP_per_capita)) +
geom_histogram(binwidth=.025, fill="#50C878") + ggtitle("2021 GDP") + xlab("GDP") + ylab("Country Count") + geom_vline(data=israel, aes(xintercept=GDP_per_capita, color="#E13F2A"),linetype="solid") + geom_vline(data=zimbabwe, aes(xintercept=GDP_per_capita, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("Zimbabwe", "Israel")) +theme_linedraw()
ggplot(hap2021, aes(x=Generosity)) +
geom_histogram(binwidth=.025, fill="#50C878") + ggtitle("2021 Generosity") + xlab("Generosity") + ylab("Country Count") + geom_vline(data=israel, aes(xintercept=Generosity, color="#E13F2A"),linetype="solid") + geom_vline(data=zimbabwe, aes(xintercept=Generosity, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("Zimbabwe", "Israel")) +theme_linedraw()
ggplot(hap2021, aes(x=Health)) +
geom_histogram(binwidth=.025, fill="#50C878") + ggtitle("2021 Health") + xlab("Health") + ylab("Country Count") + geom_vline(data=israel, aes(xintercept=Health, color="#E13F2A"),linetype="solid") + geom_vline(data=zimbabwe, aes(xintercept=Health, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("Zimbabwe", "Israel")) +theme_linedraw()
ggplot(hap2021, aes(x=Freedom)) +
geom_histogram(binwidth=.025, fill="#50C878") + ggtitle("2021 Freedom") + xlab("Freedom") + ylab("Country Count") + geom_vline(data=israel, aes(xintercept=Freedom, color="#E13F2A"),linetype="solid") + geom_vline(data=zimbabwe, aes(xintercept=Freedom, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("Zimbabwe", "Israel")) +theme_linedraw()
ggplot(hap2021, aes(x=Corruption)) +
geom_histogram(binwidth=.025, fill="#50C878") + ggtitle("2021 Corruption") + xlab("Corruption") + ylab("Country Count") + geom_vline(data=israel, aes(xintercept=Corruption, color="#E13F2A"),linetype="solid") + geom_vline(data=zimbabwe, aes(xintercept=Corruption, color="#3FE0D0"),linetype="solid") +scale_color_discrete(name = "Legend", labels = c("Zimbabwe", "Israel")) +theme_linedraw()
prednew=predict(regressor1,newdata = test_set2)
cor(prednew,test_set2$Score)
residuals2=(prednew-test_set2$Score)
mse2=mean(residuals2)
mse2
